{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development of a User-Friendly Tool for Clinicians\n",
    "\n",
    "To facilitate the use of this predictive model in clinical practice, we can develop a user-friendly tool that allows clinicians to input patient data and receive a prediction of recurrence risk. This tool can be implemented as a web application with the following features:\n",
    "\n",
    "1. Input Form: A simple form where clinicians can input patient details such as age, gender, smoking history, radiotherapy history, thyroid function, physical examination findings, pathology, tumor focality, risk category, T, N, M stages, and treatment response.\n",
    "\n",
    "2. Prediction Output: The tool will provide a prediction of recurrence risk, along with confidence scores and suggested follow-up actions based on the prediction.\n",
    "\n",
    "3. Data Visualization: Visual aids like risk charts and ROC curves can help clinicians understand the predictive model's output and make informed decisions.\n",
    "\n",
    "4. Documentation and Guidance: The tool should include documentation on how to use it and interpret the results, along with guidelines for follow-up actions based on different risk levels.\n",
    "\n",
    "## Implementation Example Using Streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model loaded successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      " * Restarting with stat\n",
      "INFO:werkzeug: * Restarting with stat\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/traitlets/config/application.py\", line 1074, in launch_instance\n",
      "    app.initialize(argv)\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/traitlets/config/application.py\", line 118, in inner\n",
      "    return method(app, *args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 692, in initialize\n",
      "    self.init_sockets()\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 331, in init_sockets\n",
      "    self.shell_port = self._bind_socket(self.shell_socket, self.shell_port)\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 253, in _bind_socket\n",
      "    return self._try_bind_socket(s, port)\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 229, in _try_bind_socket\n",
      "    s.bind(\"tcp://%s:%i\" % (self.ip, port))\n",
      "  File \"/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/zmq/sugar/socket.py\", line 302, in bind\n",
      "    super().bind(addr)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 564, in zmq.backend.cython.socket.Socket.bind\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 28, in zmq.backend.cython.checkrc._check_rc\n",
      "zmq.error.ZMQError: Address already in use (addr='tcp://127.0.0.1:9007')\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "import pickle\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# Load the pre-trained model\n",
    "try:\n",
    "    with open('TCP_logistic_regression_model.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    logging.info(\"Model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading model: {e}\")\n",
    "\n",
    "# Define the home route\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "# Define the prediction route\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        data = request.form.to_dict()\n",
    "        logging.debug(f\"Received data: {data}\")\n",
    "        \n",
    "        # Convert input data to float and reshape for prediction\n",
    "        data = list(map(float, data.values()))\n",
    "        features = np.array(data).reshape(1, -1)\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = model.predict(features)\n",
    "        probability = model.predict_proba(features)[:, 1]\n",
    "        \n",
    "        logging.info(f\"Prediction: {prediction[0]}, Probability: {probability[0]}\")\n",
    "        \n",
    "        return render_template('index.html', prediction=prediction[0], probability=probability[0])\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during prediction: {e}\")\n",
    "        return jsonify({\"error\": \"An error occurred during prediction. Please check your input and try again.\"}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m jsonify({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred during prediction. Please check your input and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m}), \u001b[38;5;241m500\u001b[39m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 48\u001b[0m     \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/flask/app.py:615\u001b[0m, in \u001b[0;36mFlask.run\u001b[0;34m(self, host, port, debug, load_dotenv, **options)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwerkzeug\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_simple\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 615\u001b[0m     \u001b[43mrun_simple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;66;03m# reset the first request information if the development server\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;66;03m# reset normally.  This makes it possible to restart the server\u001b[39;00m\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;66;03m# without reloader and that stuff from an interactive shell.\u001b[39;00m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_first_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/werkzeug/serving.py:1099\u001b[0m, in \u001b[0;36mrun_simple\u001b[0;34m(hostname, port, application, use_reloader, use_debugger, use_evalex, extra_files, exclude_patterns, reloader_interval, reloader_type, threaded, processes, request_handler, static_files, passthrough_errors, ssl_context)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_reloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_with_reloader\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m     \u001b[43mrun_with_reloader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserve_forever\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_patterns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_patterns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreloader_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreloader_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreloader_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1107\u001b[0m     srv\u001b[38;5;241m.\u001b[39mserver_close()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/werkzeug/_reloader.py:456\u001b[0m, in \u001b[0;36mrun_with_reloader\u001b[0;34m(main_func, extra_files, exclude_patterns, interval, reloader_type)\u001b[0m\n\u001b[1;32m    454\u001b[0m             reloader\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 456\u001b[0m         \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestart_with_reloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Error loading model: [Errno 2] No such file or directory: 'random_forest_model.pkl'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5001\n",
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5001\n",
      "Press CTRL+C to quit\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "import pickle\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# Load the pre-trained model\n",
    "try:\n",
    "    with open('TCP_logistig_regression_model.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    logging.info(\"Model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading model: {e}\")\n",
    "\n",
    "# Define the home route\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "# Define the prediction route\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        data = request.form.to_dict()\n",
    "        logging.debug(f\"Received data: {data}\")\n",
    "        \n",
    "        # Convert input data to float and reshape for prediction\n",
    "        data = list(map(float, data.values()))\n",
    "        features = np.array(data).reshape(1, -1)\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = model.predict(features)\n",
    "        probability = model.predict_proba(features)[:, 1]\n",
    "        \n",
    "        logging.info(f\"Prediction: {prediction[0]}, Probability: {probability[0]}\")\n",
    "        \n",
    "        return render_template('index.html', prediction=prediction[0], probability=probability[0])\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during prediction: {e}\")\n",
    "        return jsonify({\"error\": \"An error occurred during prediction. Please check your input and try again.\"}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, port=5001, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
